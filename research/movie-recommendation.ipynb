{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89fb9310",
   "metadata": {},
   "source": [
    "> Importing Necessary Dependencies\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bf7710",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import ast\n",
    "import nltk\n",
    "import zipfile\n",
    "import gdown\n",
    "import pickle\n",
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71884c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the notebook file path to the root of the project directory\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bdab8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose GPU if available, else CPU\n",
    "device = (\n",
    "    \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")  \n",
    "# Print the selected device\n",
    "print(\"Device : \", device)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380ecd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Variables\n",
    "GOOGLE_DRIVE_FILE_ID = \"1PMwyTlpKh-1IThTmTHRYxd1pjIsn5HYd\"\n",
    "DATA_DOWNLOADED_PATH = \"./data/final.csv\"\n",
    "SAVED_EMBEDDING_PATH = \"./models/movie_embeddings.pkl\"\n",
    "MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c461669",
   "metadata": {},
   "source": [
    "> Data Ingestion & Loading\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52bbfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Ingestion\n",
    "def download_and_extract(file_id: str, zip_name=\"final-movie-data.zip\", extract_dir=\"data\"):\n",
    "    if not os.path.exists(zip_name):\n",
    "        print(\"Downloading dataset from Google Drive...\")\n",
    "        url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "        gdown.download(url, zip_name, quiet=False)\n",
    "    else:\n",
    "        print(\"Zip file already exists. Skipping download.\")\n",
    "\n",
    "    if not os.path.exists(extract_dir):\n",
    "        os.makedirs(extract_dir)\n",
    "    with zipfile.ZipFile(zip_name, \"r\") as zip_ref:\n",
    "        print(\"Extracting dataset...\")\n",
    "        zip_ref.extractall(extract_dir)\n",
    "        print(\"Extraction complete.\")\n",
    "        \n",
    "download_and_extract(file_id=GOOGLE_DRIVE_FILE_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0906ee09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading\n",
    "df = pd.read_csv(DATA_DOWNLOADED_PATH)\n",
    "df.head(3).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2e4f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape of our data\n",
    "rows, cols = df.shape\n",
    "print(\"Number of rows : \", rows)\n",
    "print(\"Number of columns : \", cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b93492f",
   "metadata": {},
   "source": [
    "> Data Transformation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bdf078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnessary columns\n",
    "df = df.drop(\n",
    "    [\n",
    "        \"positive_users\",\n",
    "        \"positive_count\",\n",
    "        \"negative_users\",\n",
    "        \"negative_count\",\n",
    "        \"vote_average\",\n",
    "        \"vote_count\",\n",
    "        \"status\",\n",
    "        \"release_date\",\n",
    "        \"revenue\",\n",
    "        \"runtime\",\n",
    "        \"budget\",\n",
    "        \"poster_path\",\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "df.head(n=3).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621f3442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ttansform and clean the genre & prodcution companies columns\n",
    "def clean_genres(x):\n",
    "    try:\n",
    "        # Convert string representation of list to actual list\n",
    "        if isinstance(x, str):\n",
    "            x = ast.literal_eval(x)\n",
    "        # Join list elements into comma-separated string\n",
    "        return \", \".join([str(i).strip() for i in x])\n",
    "    except:  # noqa: E722\n",
    "        return str(x)\n",
    "    \n",
    "df[\"genres\"] = df[\"genres\"].apply(clean_genres)\n",
    "df[\"production_companies\"] = df[\"production_companies\"].apply(\n",
    "    lambda x: \", \".join([c.replace(\" \", \"\") for c in x.split(\",\")])\n",
    ")\n",
    "df.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5637d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat all the transformed features into one column\n",
    "df[\"concat_description\"] = None\n",
    "df[\"concat_description\"] = (\n",
    "    df[\"overview\"].astype(str)\n",
    "    + \" \"\n",
    "    + df[\"genres\"].astype(str)\n",
    "    + \" \"\n",
    "    + df[\"production_companies\"].astype(str)\n",
    "    + \" \"\n",
    "    + df[\"original_language\"].astype(str)\n",
    "    + \" \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcf89a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the concated features\n",
    "df = df[[\"tmdb_id\", \"title\", \"concat_description\", \"genres\"]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bb7b56",
   "metadata": {},
   "source": [
    "> Data Preparation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2987d796",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions to clean the concated description\n",
    "\n",
    "def make_lower_case(text):\n",
    "    text_lower = None\n",
    "    text_lower = text.lower()\n",
    "    return text_lower\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    text = text.split()\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    removed_stop_word_text = None\n",
    "    filtered_words = [word for word in text if word not in stop_words]\n",
    "    removed_stop_word_text = \" \".join(filtered_words)\n",
    "    return removed_stop_word_text\n",
    "\n",
    "def remove_numbers(text):\n",
    "    pattern = r\"[0-9]\"\n",
    "    removed_numbers_text = re.sub(pattern, \"\", text)\n",
    "    return removed_numbers_text\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    tokenizer = RegexpTokenizer(r\"[\\w-]+\")\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    removed_punctuation_text = \" \".join(tokens)\n",
    "    return removed_punctuation_text\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatized = [lemmatizer.lemmatize(token.lower()) for token in tokens]\n",
    "    return \" \".join(lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd94ef6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply the cleaninf functions defined above\n",
    "df_cleaned = df.copy()\n",
    "df_cleaned[\"cleaned_description\"] = (\n",
    "    df[\"concat_description\"]\n",
    "    .apply(make_lower_case)\n",
    "    .apply(remove_punctuation)\n",
    "    .apply(remove_numbers)\n",
    "    .apply(lemmatize_text)\n",
    "    .apply(remove_stop_words)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc3914c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase the weight of genres in the concated description\n",
    "def weighted_description(row, genre_weight=3):\n",
    "    # split the comma-separated genre string into a list of words\n",
    "    genres_list = [g.strip() for g in row[\"genres\"].split(\",\")]\n",
    "    # repeat genres\n",
    "    genres_weighted = \" \".join(genres_list * genre_weight)\n",
    "    # concatenate with cleaned description\n",
    "    return row[\"cleaned_description\"] + \" \" + genres_weighted\n",
    "\n",
    "df_cleaned[\"weighted_description\"] = df_cleaned.apply(weighted_description, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7547aa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View a sample of our feature weighted_description\n",
    "df_cleaned.loc[0, \"weighted_description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6248c0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert your movie descriptions column to a list\n",
    "descriptions = df_cleaned[\"weighted_description\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912cc586",
   "metadata": {},
   "source": [
    "> Modeling\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6627ad1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and load the pretrained huggingface embedding model\n",
    "embedding = HuggingFaceEmbeddings(model_name=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e68d637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute movie embedding using our dataset\n",
    "if os.path.exists(SAVED_EMBEDDING_PATH):\n",
    "    print(\"Loading precomputed movie embeddings...\")\n",
    "    with open(SAVED_EMBEDDING_PATH, \"rb\") as f:\n",
    "        movie_embedding = pickle.load(f)\n",
    "else:\n",
    "    print(\"Computing movie embeddings...\")\n",
    "    movie_embedding = np.array(embedding.embed_documents(descriptions))\n",
    "    with open(SAVED_EMBEDDING_PATH, \"wb\") as f:\n",
    "        pickle.dump(movie_embedding, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466919b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to recommend movie using the movie embedding computed above\n",
    "def content_based_recommend(movie_title, df, embeddings=movie_embedding, N=10):\n",
    "    idx = df[df[\"title\"] == movie_title].index[0]\n",
    "    movie_vec = embeddings[idx].reshape(1, -1)\n",
    "    sims = cosine_similarity(movie_vec, embeddings).flatten()\n",
    "    top_indices = sims.argsort()[::-1][1 : N + 1]\n",
    "    return [(df.iloc[i][\"title\"], round(float(sims[i]), 3)) for i in top_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3d243c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the movie embedding\n",
    "movie_title = \"The Addams Family\"\n",
    "result = content_based_recommend(\n",
    "    movie_title=movie_title, df=df_cleaned, embeddings=movie_embedding, N=10\n",
    ")\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
